{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "digits = datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   0.   5. ...,   0.   0.   0.]\n [  0.   0.   0. ...,  10.   0.   0.]\n [  0.   0.   0. ...,  16.   9.   0.]\n ..., \n [  0.   0.   1. ...,   6.   0.   0.]\n [  0.   0.   2. ...,  12.   0.   0.]\n [  0.   0.  10. ...,  12.   1.   0.]]\n"
     ]
    }
   ],
   "source": [
    "# The digits dataset\n",
    "print(digits.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 8, 9, 8])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,   0.,   5.,  13.,   9.,   1.,   0.,   0.],\n       [  0.,   0.,  13.,  15.,  10.,  15.,   5.,   0.],\n       [  0.,   3.,  15.,   2.,   0.,  11.,   8.,   0.],\n       [  0.,   4.,  12.,   0.,   0.,   8.,   8.,   0.],\n       [  0.,   5.,   8.,   0.,   0.,   9.,   8.,   0.],\n       [  0.,   4.,  11.,   0.,   1.,  12.,   7.,   0.],\n       [  0.,   2.,  14.,   5.,  10.,  12.,   0.,   0.],\n       [  0.,   0.,   6.,  13.,  10.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=100.0, cache_size=200, class_weight=None, coef0=0.0,\n  decision_function_shape=None, degree=3, gamma=0.001, kernel='rbf',\n  max_iter=-1, probability=False, random_state=None, shrinking=True,\n  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In scikit-learn, an estimator for classification is a Python object that implements the methods fit(X, y) and predict(T).\n",
    "# http://scikit-learn.org/stable/tutorial/basic/tutorial.html\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(gamma=0.001, C=100.)\n",
    "clf.fit(digits.data[:-1], digits.target[:-1]) # train on all but last digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict last digit we didn't train on\n",
    "clf.predict(digits.data[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  1.4  0.2]\n [ 4.9  3.   1.4  0.2]\n [ 4.7  3.2  1.3  0.2]\n [ 4.6  3.1  1.5  0.2]\n [ 5.   3.6  1.4  0.2]\n [ 5.4  3.9  1.7  0.4]\n [ 4.6  3.4  1.4  0.3]\n [ 5.   3.4  1.5  0.2]\n [ 4.4  2.9  1.4  0.2]\n [ 4.9  3.1  1.5  0.1]]\n"
     ]
    }
   ],
   "source": [
    "# The iris dataset\n",
    "print(iris.data[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#It is possible to save a model in the scikit by using Python’s built-in persistence model, namely pickle:\n",
    "#from sklearn import svm\n",
    "#from sklearn import datasets\n",
    "clf = svm.SVC()\n",
    "#iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "clf.fit(X, y) \n",
    "\n",
    "import pickle\n",
    "s = pickle.dumps(clf)\n",
    "clf2 = pickle.loads(s) \n",
    "clf2.predict(X[0:1]) # Predicts using pickled classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In the specific case of the scikit, it may be more interesting to use joblib’s replacement of pickle (joblib.dump & joblib.load), which is more efficient on big data, but can only pickle to the disk and not to a string:\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(clf, 'filename.pkl') \n",
    "clf3 = joblib.load('filename.pkl') \n",
    "clf3.predict(X[0:1]) # Predicts using pickled classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scikit-learn estimators follow certain rules to make their behavior more predictive.\n",
    "#Unless otherwise specified, input will be cast to float64:\n",
    "import numpy as np\n",
    "from sklearn import random_projection\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.rand(10, 2000)\n",
    "X = np.array(X, dtype='float32')\n",
    "X.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this example, X is float32, which is cast to float64 by fit_transform(X).\n",
    "transformer = random_projection.GaussianRandomProjection()\n",
    "X_new = transformer.fit_transform(X)\n",
    "X_new.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Regression targets are cast to float64, classification targets are maintained:\n",
    "#Here, the first predict() returns an integer array, since iris.target (an integer array) was used in fit. The second predict() returns a string array, since iris.target_names was for fitting.\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import SVC\n",
    "iris = datasets.load_iris()\n",
    "clf = SVC()\n",
    "clf.fit(iris.data, iris.target) \n",
    "list(clf.predict(iris.data[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['setosa', 'setosa', 'setosa']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This time we fit using the string names as the classes \n",
    "# and get back string named classes\n",
    "clf.fit(iris.data, iris.target_names[iris.target])\n",
    "list(clf.predict(iris.data[:3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyper-parameters of an estimator can be updated after it has been constructed via the sklearn.pipeline.Pipeline.set_params method. Calling fit() more than once will overwrite what was learned by any previous fit():\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "X = rng.rand(100, 10)\n",
    "y = rng.binomial(1, 0.5, 100)\n",
    "X_test = rng.rand(5, 10)\n",
    "\n",
    "clf = SVC()\n",
    "clf.set_params(kernel='linear').fit(X, y)  \n",
    "\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now change kernel to rbf and refit\n",
    "clf.set_params(kernel='rbf').fit(X, y)  \n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# When using multiclass classifiers, the learning and prediction task that is performed is dependent on the format of the target data fit upon:\n",
    "# In the [below] case, the classifier is fit on a 1d array of multiclass labels and the predict() method therefore provides corresponding multiclass predictions. It is also possible to fit upon a 2d array of binary label indicators:\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "X = [[1, 2], [2, 4], [4, 5], [3, 2], [3, 1]]\n",
    "y = [0, 0, 1, 1, 2]\n",
    "\n",
    "classif = OneVsRestClassifier(estimator=SVC(random_state=0))\n",
    "classif.fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0]\n [1 0 0]\n [0 1 0]\n [0 1 0]\n [0 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0],\n       [1, 0, 0],\n       [0, 1, 0],\n       [0, 0, 0],\n       [0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here, the classifier is fit() on a 2d binary label representation of y, using the LabelBinarizer. In this case predict() returns a 2d array representing the corresponding multilabel predictions.\n",
    "y = LabelBinarizer().fit_transform(y)\n",
    "print(y)\n",
    "classif.fit(X, y).predict(X)\n",
    "# I.e. I one hot-encoded Y, so it returns it one-hot-encoded as its predictions\n",
    "# Note that the fourth and fifth instances returned all zeroes, indicating that they matched none of the three labels fit upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0 0]\n [1 0 1 0 0]\n [0 1 0 1 0]\n [1 0 1 1 0]\n [0 0 1 0 1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0, 0],\n       [1, 0, 1, 0, 0],\n       [0, 1, 0, 1, 0],\n       [1, 0, 1, 0, 0],\n       [1, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With multilabel outputs, it is similarly possible for an instance to be assigned multiple labels:\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "# In this case, the classifier is fit upon instances each assigned multiple labels. The MultiLabelBinarizer is used to binarize the 2d array of multilabels to fit upon. As a result, predict() returns a 2d array with multiple predicted labels for each instance.\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "y = [[0, 1], [0, 2], [1, 3], [0, 2, 3], [2, 4]]\n",
    "y = MultiLabelBinarizer().fit_transform(y)\n",
    "print(y)\n",
    "classif.fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}